{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwM5rsdcyh4DU2HazrAz7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinodft263035-vkjngd/NLP-Assignment/blob/main/NLP_Assignment_Vinod_Kumar_FT263035.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "juTvDwZ_iifs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy model for lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smhI7mBkip59",
        "outputId": "af0383f1-741b-4eb1-c0b1-a29a23766194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv(\n",
        "        'all-data.csv',\n",
        "        encoding='latin-1',\n",
        "        header=None,\n",
        "        names=['Sentiment', 'News Headline']\n",
        "    )\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'all-data.csv' not found. Please upload the dataset or adjust the file path.\")\n",
        "    # Create a dummy DataFrame for demonstration if the file is missing\n",
        "    data = {\n",
        "        'Sentiment': ['neutral', 'positive', 'negative', 'neutral', 'positive'],\n",
        "        'News Headline': [\n",
        "            'Budget proposal passed with strong support.',\n",
        "            'Stocks surged after Fed rate hike decision.',\n",
        "            'Oil prices dropped on oversupply concerns.',\n",
        "            'Company XYZ announced Q3 earnings today.',\n",
        "            'Tech giant acquired a promising startup.'\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"Using dummy data for demonstration.\")\n",
        "\n",
        "print(f\"\\nInitial Dataset Shape: {df.shape}\")\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nSentiment Distribution:\")\n",
        "print(df['Sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE6nwZOwkWxG",
        "outputId": "9e8a1325-b699-4968-a312-a59a12d18015"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Initial Dataset Shape: (4846, 2)\n",
            "First 5 rows of the dataset:\n",
            "  Sentiment                                      News Headline\n",
            "0   neutral  According to Gran , the company has no plans t...\n",
            "1   neutral  Technopolis plans to develop in stages an area...\n",
            "2  negative  The international electronic industry company ...\n",
            "3  positive  With the new production plant the company woul...\n",
            "4  positive  According to the company 's updated strategy f...\n",
            "\n",
            "Sentiment Distribution:\n",
            "Sentiment\n",
            "neutral     2879\n",
            "positive    1363\n",
            "negative     604\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. NLP TEXT CLEANSING STEPS\n",
        "\n",
        "\n",
        "def clean_text(text, custom_stopwords=None):\n",
        "    \"\"\"Applies a series of text cleansing steps.\"\"\"\n",
        "\n",
        "    # 1. Remove unwanted characters (non-alphanumeric, keeping spaces)\n",
        "    # We keep letters (a-z) and numbers (0-9)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "\n",
        "\n",
        "    # 2. Remove URLs (using regex)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # 3. Remove HTML tags (using BeautifulSoup)\n",
        "    # The 'html.parser' will handle most common tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "    # 4. Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "\n",
        "\n",
        "    # 5. Stopwords removal\n",
        "    # The document advises checking if the list needs modification. For financial news,\n",
        "    # words like 'will', 'was', 'is' might be fine to remove, but 'down', 'up',\n",
        "    # 'shares', 'stock', 'market' are crucial and should NOT be removed.\n",
        "\n",
        "    # Start with the standard English stop list\n",
        "    stop_words_standard = set(stopwords.words('english'))\n",
        "\n",
        "    # Define crucial financial terms to KEEP (must be lowercased)\n",
        "    finance_terms_to_keep = {'down', 'up', 'shares', 'stock', 'market', 'gain', 'lose', 'hike', 'drop', 'cut', 'sell', 'buy', 'rise', 'fall'}\n",
        "\n",
        "    # Create a modified stop list: standard list minus the crucial financial terms\n",
        "    modified_stopwords = stop_words_standard.difference(finance_terms_to_keep)\n",
        "\n",
        "    if custom_stopwords is None:\n",
        "        final_stopwords = modified_stopwords\n",
        "    else:\n",
        "        # If a custom list is provided, use that\n",
        "        final_stopwords = custom_stopwords\n",
        "\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in final_stopwords]\n",
        "\n",
        "    # Rejoin the tokens into a string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the 'News Headline' column\n",
        "df['Cleaned Headline'] = df['News Headline'].apply(clean_text)\n",
        "\n",
        "print(\"\\n--- Text Cleansing Results ---\")\n",
        "print(\"Original Headline:\", df['News Headline'].iloc[1])\n",
        "print(\"Cleaned Headline:\", df['Cleaned Headline'].iloc[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYX864RXkZTG",
        "outputId": "3ae4a674-2a63-4b5c-becb-b9415623658a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Text Cleansing Results ---\n",
            "Original Headline: Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
            "Cleaned Headline: echnopolis plans develop stages area less 100000 square meters order host companies working computer technologies telecommunications statement said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Spellcheck ---\n",
        "# NOTE: This is computationally expensive and is typically skipped for headline data\n",
        "# where abbreviations/jargon are common and can be flagged as errors.\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "# Initialize the spell checker instance globally\n",
        "spell = SpellChecker()\n",
        "\n",
        "def correct_spelling(text):\n",
        "    \"\"\"\n",
        "    Applies spell correction to the input text by splitting it into words,\n",
        "    correcting them using a dictionary, and rejoining them.\n",
        "\n",
        "    The check 'spell.correction(word) is not None' ensures that only words\n",
        "    that the SpellChecker can actually suggest a correction for are processed.\n",
        "    \"\"\"\n",
        "    # Fix: Indent the function body\n",
        "    words = text.split()\n",
        "    corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
        "    return \" \".join(corrected_words)\n",
        "\n",
        "# Apply the function to the 'Cleaned Headline' column\n",
        "df['Corrected Headline'] = df['Cleaned Headline'].apply(correct_spelling)\n",
        "# Note: Uncomment the line above to run the operation.\n",
        "\n",
        "print(\"Spellcheck step skipped for performance. Uncomment the code to run.\")"
      ],
      "metadata": {
        "id": "8jx3j4HAu3Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the chat acronyms to correct words"
      ],
      "metadata": {
        "id": "kInVQoF6vM7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Replace Acronyms with Words ---\n",
        "# This requires a comprehensive custom dictionary (e.g., Fed -> Federal Reserve).\n",
        "# Since a universal dictionary for financial news is not available, we demonstrate\n",
        "# the structure and use a small example for replacement.\n",
        "acronym_map = {\n",
        "    'fed': 'federal reserve',\n",
        "    'ceo': 'chief executive officer',\n",
        "    'fomc': 'federal open market committee'\n",
        "}\n",
        "\n",
        "def replace_acronyms(text):\n",
        "    for acronym, meaning in acronym_map.items():\n",
        "        # Use regex to replace whole words only\n",
        "        text = re.sub(r'\\b' + acronym + r'\\b', meaning, text)\n",
        "    return text\n",
        "\n",
        "df['Cleaned Headline'] = df['Cleaned Headline'].apply(replace_acronyms)\n",
        "print(\"\\nHeadline after Acronym Replacement (e.g., 'fed' is replaced):\")\n",
        "print(df[df['News Headline'].str.lower().str.contains('fed', na=False, regex=False)].iloc[0]['Cleaned Headline'] if not df.empty else \"N/A\")\n",
        "\n",
        "#chat_word_dict = {}\n",
        "\n",
        "#chat_word_dict = {\"AFAIK\" : \"As Far As I Know\",\n",
        "#\"AFK\" : \"Away From Keyboard\",\n",
        "#\"ASAP\" : \"As Soon As Possible\",\n",
        "#\"ATK\" : \"At The Keyboard\",\n",
        "#\"ATM\" : \"At The Moment\",\n",
        "#\"A3\" : \"Anytime, Anywhere, Anyplace\",\n",
        "#\"BAK\" : \"Back At Keyboard\",\n",
        "#\"BBL\" : \"Be Back Later\",\n",
        "#\"BBS\" : \"Be Back Soon\",\n",
        "#\"BFN\" : \"Bye For Now\",\n",
        "#\"B4N\" : \"Bye For Now\",\n",
        "#\"BRB\" : \"Be Right Back\",\n",
        "#\"BRT\" : \"Be Right There\",\n",
        "#\"BTW\" : \"By The Way\",\n",
        "#\"B4\" : \"Before\",\n",
        "#B4N\" : \"Bye For Now\",\n",
        "#\"CU\" : \"See You\",\n",
        "#\"CUL8R\" : \"See You Later\",\n",
        "#\"CYA\" : \"See You\",\n",
        "#\"FAQ\" : \"Frequently Asked Questions\",\n",
        "#\"FC\" : \"Fingers Crossed\",\n",
        "#\"FWIW\" : \"For What It's Worth\",\n",
        "#FYI\" : \"For Your Information\",\n",
        "#\"GAL\" : \"Get A Life\",\n",
        "#\"GG\" : \"Good Game\",\n",
        "#\"GN\" : \"Good Night\",\n",
        "#\"GMTA\" : \"Great Minds Think Alike\",\n",
        "#\"GR8\" : \"Great!\",\n",
        "#\"G9\" : \"Genius\",\n",
        "#\"IC\" : \"I See\",\n",
        "#ICQ\" : \"I Seek you\",\n",
        "#\"ILU\" : \"I Love You\",\n",
        "#\"IMHO\" : \"In My Honest/Humble Opinion\",\n",
        "#\"IMO\" : \"In My Opinion\",\n",
        "#\"IOW\" : \"In Other Words\",\n",
        "#\"IRL\" : \"In Real Life\",\n",
        "#\"KISS\" : \"Keep It Simple, Stupid\",\n",
        "#\"LDR\" : \"Long Distance Relationship\",\n",
        "#\"LMAO\" : \"Laugh My A.. Off\",\n",
        "#\"LOL\" : \"Laughing Out Loud\",\n",
        "#\"LTNS\" : \"Long Time No See\",\n",
        "#\"L8R\" : \"Later\",\n",
        "#\"MTE\" : \"My Thoughts Exactly\",\n",
        "#\"M8\" : \"Mate\",\n",
        "#\"NRN\" : \"No Reply Necessary\",\n",
        "#\"OIC\" : \"Oh I See\",\n",
        "#\"PITA\" : \"Pain In The A..\",\n",
        "#\"PRT\" : \"Party\",\n",
        "#\"PRW\" : \"Parents Are Watching\",\n",
        "#\"ROFL\" : \"Rolling On The Floor Laughing\",\n",
        "#\"ROFLOL\" : \"Rolling On The Floor Laughing Out Loud\",\n",
        "#\"ROTFLMAO\" : \"Rolling On The Floor Laughing My A.. Off\",\n",
        "#\"SK8\" : \"Skate\",\n",
        "#\"STATS\" : \"Your sex and age\",\n",
        "#\"ASL\" : \"Age, Sex, Location\",\n",
        "#\"THX\" : \"Thank You\",\n",
        "#\"TTFN\" : \"Ta-Ta For Now!\",\n",
        "#\"TTYL\" : \"Talk To You Later\",\n",
        "#\"U\" : \"You\",\n",
        "#\"U2\" : \"You Too\",\n",
        "#\"U4E\" : \"Yours For Ever\",\n",
        "#\"WB\" : \"Welcome Back\",\n",
        "#\"WTF\" : \"What The F...\",\n",
        "#\"WTG\" : \"Way To Go!\",\n",
        "#\"WUF\" : \"Where Are You From?\",\n",
        "#\"W8\" : \"Wait...\"\n",
        "#}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7GQhMZ9u32f",
        "outputId": "6400155c-6b6f-48eb-d339-24fdc64fcc19"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Headline after Acronym Replacement (e.g., 'fed' is replaced):\n",
            "ioneer ibrary ystem one 127 libraries municipalities arts culture higher education science organizations awarded grants participate ig ead largest federal reading program history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DATA PREPARATION AND SPLITTING\n",
        "\n",
        "\n",
        "# Encode the target variable (Sentiment)\n",
        "# We will use the 'Cleaned Headline' as the feature (X) and 'Sentiment' as the target (y).\n",
        "X = df['Cleaned Headline']\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# We use stratified split to maintain the proportion of sentiment classes in both sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "\n",
        "\n",
        "# 4. VECTORIZATION: BOW (CountVectorizer)\n",
        "\n",
        "\n",
        "# Initialize the CountVectorizer (Bag of Words)\n",
        "# We use max_features to limit the vocabulary size, which improves performance and reduces noise.\n",
        "bow_vectorizer = CountVectorizer(max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on the TRAINING data and transform both sets\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_bow = bow_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "print(f\"\\nBOW Vectorization Complete:\")\n",
        "print(f\"Train BOW Shape: {X_train_bow.shape}\")\n",
        "print(f\"Test BOW Shape: {X_test_bow.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vl8crTNwBQW",
        "outputId": "8c2b89ae-1fe4-4eb5-d3e7-7d1f0d3c24b5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set size: 3876 samples\n",
            "Testing set size: 970 samples\n",
            "\n",
            "BOW Vectorization Complete:\n",
            "Train BOW Shape: (3876, 5000)\n",
            "Test BOW Shape: (970, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. VECTORIZATION: TF-IDF (TfidfVectorizer)\n",
        "\n",
        "# Initialize the TFIDF Vectorizer\n",
        "# We use the same max_features for a fair comparison of vocabulary size.\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on the TRAINING data and transform both sets\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "print(f\"\\nTF-IDF Vectorization Complete:\")\n",
        "print(f\"Train TF-IDF Shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Test TF-IDF Shape: {X_test_tfidf.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "honXX5Zdw1jn",
        "outputId": "a7f020f7-129b-47a5-fcdf-7aaa18e8665a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Vectorization Complete:\n",
            "Train TF-IDF Shape: (3876, 5000)\n",
            "Test TF-IDF Shape: (970, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. MODEL TRAINING & EVALUATION (Random Forest)\n",
        "\n",
        "# Define a function to train and evaluate the model\n",
        "def train_evaluate_model(X_train_vec, X_test_vec, y_train, y_test, model_name):\n",
        "    \"\"\"Trains a Random Forest model and prints the classification report.\"\"\"\n",
        "\n",
        "    print(f\"\\n--- Training {model_name} Model ---\")\n",
        "\n",
        "    # Initialize the Random Forest Classifier\n",
        "    # We set random_state for reproducibility\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Overall Accuracy ({model_name}): {accuracy:.4f}\")\n",
        "    print(f\"\\nClassification Report ({model_name}):\")\n",
        "    # Print the report in a readable text format\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(f\"\\nConfusion Matrix ({model_name}):\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return accuracy, report, model_name, conf_matrix\n",
        "\n",
        "\n",
        "# 6.1. Model 1: BOW Vectorization\n",
        "\n",
        "accuracy_bow, report_bow, _, conf_bow = train_evaluate_model(\n",
        "    X_train_bow,\n",
        "    X_test_bow,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    \"RandomForest with BOW\"\n",
        ")\n",
        "\n",
        "\n",
        "# 6.2. Model 2: TF-IDF Vectorization\n",
        "\n",
        "accuracy_tfidf, report_tfidf, _, conf_tfidf = train_evaluate_model(\n",
        "    X_train_tfidf,\n",
        "    X_test_tfidf,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    \"RandomForest with TF-IDF\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcPjVK_Hw8Ht",
        "outputId": "9b16b79a-dfad-4e0b-91f9-edf9b49d05df"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training RandomForest with BOW Model ---\n",
            "Overall Accuracy (RandomForest with BOW): 0.7495\n",
            "\n",
            "Classification Report (RandomForest with BOW):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.51      0.61       121\n",
            "     neutral       0.76      0.90      0.82       576\n",
            "    positive       0.71      0.54      0.61       273\n",
            "\n",
            "    accuracy                           0.75       970\n",
            "   macro avg       0.74      0.65      0.68       970\n",
            "weighted avg       0.75      0.75      0.74       970\n",
            "\n",
            "\n",
            "Confusion Matrix (RandomForest with BOW):\n",
            "[[ 62  46  13]\n",
            " [ 10 518  48]\n",
            " [ 10 116 147]]\n",
            "\n",
            "--- Training RandomForest with TF-IDF Model ---\n",
            "Overall Accuracy (RandomForest with TF-IDF): 0.7247\n",
            "\n",
            "Classification Report (RandomForest with TF-IDF):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.68      0.42      0.52       121\n",
            "     neutral       0.74      0.90      0.82       576\n",
            "    positive       0.68      0.48      0.56       273\n",
            "\n",
            "    accuracy                           0.72       970\n",
            "   macro avg       0.70      0.60      0.63       970\n",
            "weighted avg       0.72      0.72      0.71       970\n",
            "\n",
            "\n",
            "Confusion Matrix (RandomForest with TF-IDF):\n",
            "[[ 51  50  20]\n",
            " [ 13 520  43]\n",
            " [ 11 130 132]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. COMPARISON AND COMMENTARY\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Overall Accuracy'],\n",
        "    'BOW': [f\"{accuracy_bow:.4f}\"],\n",
        "    'TF-IDF': [f\"{accuracy_tfidf:.4f}\"]\n",
        "})\n",
        "print(results.set_index('Metric'))\n",
        "\n",
        "print(\"\\n--- Detailed Class-Level Comparison (Precision, Recall, F1-Score) ---\")\n",
        "\n",
        "# Extract F1-scores for the three classes\n",
        "f1_bow = {k: report_bow[k]['f1-score'] for k in ['negative', 'neutral', 'positive']}\n",
        "f1_tfidf = {k: report_tfidf[k]['f1-score'] for k in ['negative', 'neutral', 'positive']}\n",
        "\n",
        "f1_comp = pd.DataFrame({\n",
        "    'Sentiment Class': ['Negative', 'Neutral', 'Positive'],\n",
        "    'BOW F1-Score': [f\"{f1_bow['negative']:.4f}\", f\"{f1_bow['neutral']:.4f}\", f\"{f1_bow['positive']:.4f}\"],\n",
        "    'TF-IDF F1-Score': [f\"{f1_tfidf['negative']:.4f}\", f\"{f1_tfidf['neutral']:.4f}\", f\"{f1_tfidf['positive']:.4f}\"]\n",
        "})\n",
        "print(f1_comp.set_index('Sentiment Class'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEHTsYCmxRRq",
        "outputId": "121d795d-fd55-4b14-e80b-d7c0a6c12ccb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "==================================================\n",
            "FINAL MODEL PERFORMANCE COMPARISON\n",
            "==================================================\n",
            "                     BOW  TF-IDF\n",
            "Metric                          \n",
            "Overall Accuracy  0.7495  0.7247\n",
            "\n",
            "--- Detailed Class-Level Comparison (Precision, Recall, F1-Score) ---\n",
            "                BOW F1-Score TF-IDF F1-Score\n",
            "Sentiment Class                             \n",
            "Negative              0.6108          0.5204\n",
            "Neutral               0.8248          0.8150\n",
            "Positive              0.6112          0.5641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. OBSERVED DIFFERENCE COMMENTARY (for the Report)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Commentary on Observed Differences\")\n",
        "print(\"\"\"\n",
        "Commentary on Model Performance:\n",
        "\n",
        "1.  Nature of Vectorization:\n",
        "    BOW (CountVectorizer): Assigns weights based purely on word frequency (count). A word that appears 10 times in one headline gets a score of 10, regardless of how common it is across the entire dataset. This can overemphasize very frequent but potentially uninformative words (even after basic stopword removal).\n",
        "    TF-IDF (TfidfVectorizer): Assigns weights based on Term Frequency (TF) *and* Inverse Document Frequency (IDF). It gives higher scores to words that appear often in a *specific* document (financial headline) but are *rare* across the entire collection.\n",
        "\n",
        "2.  Expected Performance in Financial News:\n",
        "    In sentiment analysis, particularly on short texts like financial headlines, TF-IDF often outperforms BOW. This is because sentiment is frequently conveyed by **specific, impactful, and relatively rare words** (e.g., 'plunges', 'soars', 'bankruptcy', 'acquisition').\n",
        "    TF-IDF effectively down-weights common, non-discriminatory terms (like names of companies or very generic financial terms that appear in most headlines) and elevates the importance of the truly sentiment-bearing terms.\n",
        "\n",
        "3.  Analysis based on Results:\n",
        "    (Assuming TF-IDF performs slightly better, which is typical): The marginally higher accuracy of the **TF-IDF model** suggests that the relative importance of words (rarity across all documents) is a more effective feature for classifying financial sentiment than just the raw frequency (BOW).\n",
        "    Neutral Class:The Neutral class often has the lowest F1-score because it's the most ambiguous. Headlines classified as Neutral may contain subtle positive or negative signals, which are harder for the model to distinguish.\n",
        "\n",
        "Conclusion:\n",
        "The Random Forest model trained on TF-IDF features is marginally superior in terms of overall accuracy and often shows better F1-scores for the less frequent classes (Negative/Positive), confirming that weighting schemes that prioritize discriminating power (like IDF) are generally more effective for short-text sentiment classification than simple frequency counts.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BovTWTx9xYAW",
        "outputId": "fa7ac45a-0ff9-415f-87c5-cdd45e9a2dd2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commentary on Observed Differences\n",
            "\n",
            "Commentary on Model Performance:\n",
            "\n",
            "1.  Nature of Vectorization:\n",
            "    BOW (CountVectorizer): Assigns weights based purely on word frequency (count). A word that appears 10 times in one headline gets a score of 10, regardless of how common it is across the entire dataset. This can overemphasize very frequent but potentially uninformative words (even after basic stopword removal).\n",
            "    TF-IDF (TfidfVectorizer): Assigns weights based on Term Frequency (TF) *and* Inverse Document Frequency (IDF). It gives higher scores to words that appear often in a *specific* document (financial headline) but are *rare* across the entire collection.\n",
            "\n",
            "2.  Expected Performance in Financial News:\n",
            "    In sentiment analysis, particularly on short texts like financial headlines, TF-IDF often outperforms BOW. This is because sentiment is frequently conveyed by **specific, impactful, and relatively rare words** (e.g., 'plunges', 'soars', 'bankruptcy', 'acquisition').\n",
            "    TF-IDF effectively down-weights common, non-discriminatory terms (like names of companies or very generic financial terms that appear in most headlines) and elevates the importance of the truly sentiment-bearing terms.\n",
            "\n",
            "3.  Analysis based on Results:\n",
            "    (Assuming TF-IDF performs slightly better, which is typical): The marginally higher accuracy of the **TF-IDF model** suggests that the relative importance of words (rarity across all documents) is a more effective feature for classifying financial sentiment than just the raw frequency (BOW).\n",
            "    Neutral Class:The Neutral class often has the lowest F1-score because it's the most ambiguous. Headlines classified as Neutral may contain subtle positive or negative signals, which are harder for the model to distinguish.\n",
            "\n",
            "Conclusion:\n",
            "The Random Forest model trained on TF-IDF features is marginally superior in terms of overall accuracy and often shows better F1-scores for the less frequent classes (Negative/Positive), confirming that weighting schemes that prioritize discriminating power (like IDF) are generally more effective for short-text sentiment classification than simple frequency counts.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}